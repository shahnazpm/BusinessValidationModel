{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3796459",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     ArrowDtype,\n\u001b[0;32m     49\u001b[0m     Int8Dtype,\n\u001b[0;32m     50\u001b[0m     Int16Dtype,\n\u001b[0;32m     51\u001b[0m     Int32Dtype,\n\u001b[0;32m     52\u001b[0m     Int64Dtype,\n\u001b[0;32m     53\u001b[0m     UInt8Dtype,\n\u001b[0;32m     54\u001b[0m     UInt16Dtype,\n\u001b[0;32m     55\u001b[0m     UInt32Dtype,\n\u001b[0;32m     56\u001b[0m     UInt64Dtype,\n\u001b[0;32m     57\u001b[0m     Float32Dtype,\n\u001b[0;32m     58\u001b[0m     Float64Dtype,\n\u001b[0;32m     59\u001b[0m     CategoricalDtype,\n\u001b[0;32m     60\u001b[0m     PeriodDtype,\n\u001b[0;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m---> 62\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     63\u001b[0m     StringDtype,\n\u001b[0;32m     64\u001b[0m     BooleanDtype,\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     NA,\n\u001b[0;32m     67\u001b[0m     isna,\n\u001b[0;32m     68\u001b[0m     isnull,\n\u001b[0;32m     69\u001b[0m     notna,\n\u001b[0;32m     70\u001b[0m     notnull,\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     Index,\n\u001b[0;32m     73\u001b[0m     CategoricalIndex,\n\u001b[0;32m     74\u001b[0m     RangeIndex,\n\u001b[0;32m     75\u001b[0m     MultiIndex,\n\u001b[0;32m     76\u001b[0m     IntervalIndex,\n\u001b[0;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     78\u001b[0m     DatetimeIndex,\n\u001b[0;32m     79\u001b[0m     PeriodIndex,\n\u001b[0;32m     80\u001b[0m     IndexSlice,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NaT,\n\u001b[0;32m     83\u001b[0m     Period,\n\u001b[0;32m     84\u001b[0m     period_range,\n\u001b[0;32m     85\u001b[0m     Timedelta,\n\u001b[0;32m     86\u001b[0m     timedelta_range,\n\u001b[0;32m     87\u001b[0m     Timestamp,\n\u001b[0;32m     88\u001b[0m     date_range,\n\u001b[0;32m     89\u001b[0m     bdate_range,\n\u001b[0;32m     90\u001b[0m     Interval,\n\u001b[0;32m     91\u001b[0m     interval_range,\n\u001b[0;32m     92\u001b[0m     DateOffset,\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     to_numeric,\n\u001b[0;32m     95\u001b[0m     to_datetime,\n\u001b[0;32m     96\u001b[0m     to_timedelta,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     Flags,\n\u001b[0;32m     99\u001b[0m     Grouper,\n\u001b[0;32m    100\u001b[0m     factorize,\n\u001b[0;32m    101\u001b[0m     unique,\n\u001b[0;32m    102\u001b[0m     value_counts,\n\u001b[0;32m    103\u001b[0m     NamedAgg,\n\u001b[0;32m    104\u001b[0m     array,\n\u001b[0;32m    105\u001b[0m     Categorical,\n\u001b[0;32m    106\u001b[0m     set_eng_float_format,\n\u001b[0;32m    107\u001b[0m     Series,\n\u001b[0;32m    108\u001b[0m     DataFrame,\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da45598",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\AI & DATA SCIENCE\\Sem 2\\ML 2\\Projects\\Project1\\X_train.csv\")\n",
    "X_test=pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\AI & DATA SCIENCE\\Sem 2\\ML 2\\Projects\\Project1\\X_test.csv\")\n",
    "X_val=pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\AI & DATA SCIENCE\\Sem 2\\ML 2\\Projects\\Project1\\X_val.csv\")\n",
    "y_val=pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\AI & DATA SCIENCE\\Sem 2\\ML 2\\Projects\\Project1\\y_val.csv\")\n",
    "y_train=pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\AI & DATA SCIENCE\\Sem 2\\ML 2\\Projects\\Project1\\y_train.csv\")\n",
    "y_test=pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\AI & DATA SCIENCE\\Sem 2\\ML 2\\Projects\\Project1\\y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['state','city','review_count_y','stars','elite_user_count','total_useful_votes'], axis=1)\n",
    "X_val = X_val.drop(['state','city','review_count_y','stars','elite_user_count','total_useful_votes'], axis=1)\n",
    "X_test = X_test.drop(['state','city','review_count_y','stars','elite_user_count','total_useful_votes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pd.get_dummies() to both X_train and X_test\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "X_val_encoded= pd.get_dummies(X_val)\n",
    "# Align the columns of X_test to match X_train\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca23683",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_encoded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e392e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_encoded.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034befc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in X_train_encoded\n",
    "X_train_encoded_clean = X_train_encoded.dropna()\n",
    "\n",
    "# Make sure to drop corresponding rows in y_train using the same index\n",
    "y_train_clean = y_train.loc[X_train_encoded_clean.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e08a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_encoded_clean.shape)\n",
    "print(y_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_encoded_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smote.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92a868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(\n",
    "                                     max_depth=10,               # Limit the depth of the tree\n",
    "    min_samples_split=10,        # Require at least 10 samples to split an internal node\n",
    "    min_samples_leaf=10,          # Require at least 5 samples at leaf nodes\n",
    "    max_leaf_nodes=100,           # Limit the number of leaf nodes\n",
    "    max_features='sqrt',         # Use the square root of the number of features at each split (good for classification tasks)\n",
    "    random_state=42              # Ensures reproducibility\n",
    "                                 )\n",
    "dt_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857d7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on the training data\n",
    "y_train_pred = dt_model.predict(X_train_smote)\n",
    "\n",
    "# Calculate and print training accuracy\n",
    "training_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "print(f\"Training Accuracy: {training_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8d75e54",
   "metadata": {},
   "source": [
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "#Align the columns of X_test to match X_train\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71437fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on val data\n",
    "y_pred_dt = dt_model.predict(X_val_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree validation Accuracy :\", accuracy_score(y_val, y_pred_dt))\n",
    "print(classification_report(y_val, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance = dt_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_names = X_train_encoded.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Top 10 Feature Importance from DecisionTreeClassifier')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Add the feature importance values beside the bars\n",
    "for index, value in enumerate(importance_df['Importance']):\n",
    "    plt.text(value, index, f'{value:.3f}', va='center')  # Format to 4 decimal places\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f559825",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote['RestaurantsPriceRange2']=X_train_smote['RestaurantsPriceRange2'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d875108",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc50db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training data\n",
    "y_train_pred = dt_model.predict(X_train_smote)\n",
    "\n",
    "# Calculate and print training accuracy\n",
    "training_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "print(f\"Training Accuracy: {training_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2583b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on val data\n",
    "y_pred_dt = dt_model.predict(X_val_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_val, y_pred_dt))\n",
    "print(classification_report(y_val, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80730c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_2 = dt_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_names = X_train_encoded.columns\n",
    "importance_df_2 = pd.DataFrame({'Feature': feature_names, 'Importance': importance_2})\n",
    "importance_df_2 = importance_df_2.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_2)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Top 20 Feature Importance from DecisionTreeClassifier')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Add the feature importance values beside the bars\n",
    "for index, value in enumerate(importance_df_2['Importance']):\n",
    "    plt.text(value, index, f'{value:.3f}', va='center')  # Format to 4 decimal places\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a16c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote['RestaurantsPriceRange2']=X_train_smote['RestaurantsPriceRange2'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aeb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training data\n",
    "y_train_pred = dt_model.predict(X_train_smote)\n",
    "\n",
    "# Calculate and print training accuracy\n",
    "training_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "print(f\"Training Accuracy: {training_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on val data\n",
    "y_pred_dt = dt_model.predict(X_val_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_val, y_pred_dt))\n",
    "print(classification_report(y_val, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_3 = dt_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_names = X_train_encoded.columns\n",
    "importance_df_3 = pd.DataFrame({'Feature': feature_names, 'Importance': importance_3})\n",
    "importance_df_3 = importance_df_3.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_3)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Top 20 Feature Importance from DecisionTreeClassifier')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Add the feature importance values beside the bars\n",
    "for index, value in enumerate(importance_df_3['Importance']):\n",
    "    plt.text(value, index, f'{value:.3f}', va='center')  # Format to 4 decimal places\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bf723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [5,10, 15],\n",
    "    'min_samples_split': [2, 5, 10,20],\n",
    "    'min_samples_leaf': [1,3,5,7,10],\n",
    "    'max_leaf_nodes': [20,40,60,80,100],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=dt_model, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           scoring='accuracy',  # Use accuracy as the scoring metric\n",
    "                           n_jobs=-1,  # Use all available cores\n",
    "                           verbose=2)  # Print progress\n",
    "\n",
    "# Fit the model using Grid Search\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Cross-Validation Score: {:.4f}\".format(best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182537df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree Classifier\n",
    "best_model = DecisionTreeClassifier(**best_params)\n",
    "best_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training data\n",
    "y_train_pred = best_model.predict(X_train_smote)\n",
    "\n",
    "# Calculate and print training accuracy\n",
    "training_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "print(f\"Training Accuracy: {training_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred_dt = best_model.predict(X_test_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_best_model = best_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_names = X_train_encoded.columns\n",
    "importance_df__best_model = pd.DataFrame({'Feature': feature_names, 'Importance': importance_best_model})\n",
    "importance_df__best_model = importance_df__best_model.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df__best_model)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Top 20 Feature Importance from DecisionTreeClassifier')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Add the feature importance values beside the bars\n",
    "for index, value in enumerate(importance_df__best_model['Importance']):\n",
    "    plt.text(value, index, f'{value:.3f}', va='center')  # Format to 4 decimal places\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c3ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative values\n",
    "negative_values = (X_train_encoded < 0).sum()\n",
    "print(\"Negative values per feature:\\n\", negative_values)\n",
    "\n",
    "# Check for zero values\n",
    "zero_values = (X_train_encoded == 0).sum()\n",
    "print(\"Zero values per feature:\\n\", zero_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e10f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "# Now use X_train_scaled and X_test_scaled for LIME\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train_scaled,  # Scaled training data\n",
    "    feature_names=X_train_encoded.columns,  # Feature names\n",
    "    class_names=['Class 0', 'Class 1'],  # Adjust based on your problem\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Pick a sample from the test set to explain\n",
    "i = 10\n",
    "sample = X_test_scaled[i].reshape(1, -1)\n",
    "\n",
    "# Generate explanation\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test_scaled[i],  # Scaled instance to explain\n",
    "    predict_fn=best_model.predict_proba  # Prediction function\n",
    ")\n",
    "\n",
    "# Show explanation\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numba==1.24.0 --force-reinstall \n",
    "import shap\n",
    "\n",
    "# Initialize the SHAP explainer for the Decision Tree model\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test_encoded)\n",
    "\n",
    "# Plot SHAP summary plot for global feature importance\n",
    "shap.summary_plot(shap_values[1], X_test_encoded, feature_names=X_test_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize the SHAP explainer for the Decision Tree model\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test_encoded)\n",
    "\n",
    "# Plot SHAP values for the first prediction (or for all)\n",
    "shap.initjs()  # Initialize JS visualization in Jupyter Notebook\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_test_encoded, feature_names=X_test_encoded.columns)\n",
    "\n",
    "# You can also visualize SHAP values for a specific instance\n",
    "# For example, explaining the prediction for the first test instance\n",
    "shap.force_plot(explainer.expected_value, shap_values[1][0], X_test_encoded.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da364e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470b412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e26fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
